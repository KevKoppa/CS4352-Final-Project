{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8e8d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T18:04:19.267440Z",
     "start_time": "2023-12-03T18:03:44.015655Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4af407c3f780f9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:04:50.285377Z",
     "start_time": "2023-12-03T18:04:25.142548Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing all following data and putting in a graph\n",
    "pkl_file = open('Unfollower/15weeks_friend_dict.pkl', 'rb')\n",
    "mydict2 = pickle.load(pkl_file)\n",
    "pkl_file.close()\n",
    "\n",
    "week = 0\n",
    "for key, values in mydict2.items():\n",
    "    if len(values[week]) == 0:\n",
    "        mydict2[key] = []\n",
    "        continue\n",
    "    new = values[week][1]\n",
    "    mydict2[key] = new\n",
    "\n",
    "# mydict2 has format:\n",
    "# user_id: [following_user_id1, following_user_id2...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90ee72edadb771",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:05:26.512013Z",
     "start_time": "2023-12-03T18:05:26.421668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118640\n",
      "962\n"
     ]
    }
   ],
   "source": [
    "# forrest fire sampling implementation and use \n",
    "def forest_fire_sampling(graph_dict, initial_burn_probability, secondary_burn_probability, max_samples=None):\n",
    "    # Choose a random start node\n",
    "    random.seed(947)\n",
    "    start_node = random.choice(list(graph_dict.keys()))\n",
    "    \n",
    "    # Force starting node to have at least 100 friends \n",
    "    if len(graph_dict[start_node]) < 100:\n",
    "        start_node = random.choice(list(graph_dict.keys()))\n",
    "    sampled_nodes = set([start_node])\n",
    "    burning_nodes = set([start_node])\n",
    "    \n",
    "    while burning_nodes:\n",
    "        new_burning_nodes = set()\n",
    "        for node in burning_nodes:\n",
    "            # For each neighbor, decide if it catches fire based on the burn probability\n",
    "            for neighbor in graph_dict[node]:\n",
    "                if neighbor not in sampled_nodes:\n",
    "                    if random.random() < (initial_burn_probability if node == start_node else secondary_burn_probability):\n",
    "                        new_burning_nodes.add(neighbor)\n",
    "                        sampled_nodes.add(neighbor)\n",
    "                        if max_samples and len(sampled_nodes) >= max_samples:\n",
    "                            return sampled_nodes\n",
    "        burning_nodes = new_burning_nodes\n",
    "\n",
    "    return sampled_nodes\n",
    "\n",
    "# sampling has undeterministic results where sample may have few nodes or many nodes depending on whether random starting node has many or few neighbors. We may want to force the starting node to have more than 10 friends. \n",
    "\n",
    "sample = forest_fire_sampling(mydict2, 0.2, 0.1, max_samples=1000)\n",
    "shortened_dict = defaultdict(list)\n",
    "print(len(mydict2))\n",
    "for k in mydict2:\n",
    "    if k in sample: \n",
    "        for v in mydict2[k]:\n",
    "            if v in sample: \n",
    "                shortened_dict[k].append(v)\n",
    "\n",
    "print(len(shortened_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8979b3863b5b9b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:05:32.907587Z",
     "start_time": "2023-12-03T18:05:32.901087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Creating sample graph and drawing it \n",
    "subset_followers_graph = nx.DiGraph()\n",
    "for k, v in shortened_dict.items():\n",
    "    for neighbor in v:\n",
    "        subset_followers_graph.add_edge(k, neighbor)\n",
    "\n",
    "print(subset_followers_graph.number_of_nodes())\n",
    "\n",
    "# Draw the graph node\n",
    "nx.draw(subset_followers_graph, with_labels=False, node_size=20, node_color=(0.392, 0.584, 0.929, 0.5))\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges before removal: 25828\n",
      "edges after removal: 23246\n"
     ]
    }
   ],
   "source": [
    "removed_edges_graph = subset_followers_graph.copy()\n",
    "print(\"edges before removal:\",removed_edges_graph.number_of_edges())\n",
    "def remove_edges(G, k):\n",
    "    # Calculate the number of edges to remove (10% of total edges)\n",
    "    num_edges_to_remove = int(k * G.number_of_edges())\n",
    "    \n",
    "    # Get the list of all edges in the graph\n",
    "    all_edges = list(G.edges())\n",
    "    random.seed(947)\n",
    "    # Randomly select edges to remove\n",
    "    removed_edges = random.sample(all_edges, num_edges_to_remove)\n",
    "    \n",
    "    # Remove the selected edges from the graph\n",
    "    G.remove_edges_from(removed_edges)\n",
    "    \n",
    "    return set(removed_edges)\n",
    "\n",
    "removed_edges = remove_edges(removed_edges_graph,0.1)\n",
    "removed_nodes_set = set()\n",
    "for edge in removed_edges:\n",
    "    removed_nodes_set.add(edge[0])\n",
    "print(\"edges after removal:\", removed_edges_graph.number_of_edges())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:05:40.163823Z",
     "start_time": "2023-12-03T18:05:40.108431Z"
    }
   },
   "id": "a5e8442a92403e29"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "243ec764fc6d220e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:35:05.813177Z",
     "start_time": "2023-12-03T18:35:05.698186Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 36\u001B[0m\n\u001B[1;32m     34\u001B[0m adjacency_matrix \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((num_nodes, num_nodes), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m edge \u001B[38;5;129;01min\u001B[39;00m train_edge_list:\n\u001B[0;32m---> 36\u001B[0m     \u001B[43madjacency_matrix\u001B[49m\u001B[43m[\u001B[49m\u001B[43medge\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n\u001B[1;32m     38\u001B[0m predictions \u001B[38;5;241m=\u001B[39m model(adjacency_matrix)\n\u001B[1;32m     40\u001B[0m targets \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros_like(predictions)\n",
      "\u001B[0;31mTypeError\u001B[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "edge_list = list(subset_followers_graph.edges)\n",
    "\n",
    "# Simple GNN, might be better to test with multiple convolutional layers\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim=16):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_nodes, embedding_dim)\n",
    "        self.conv2 = GCNConv(embedding_dim, 1)  # Output 1 for edge prediction\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = torch.ones((num_nodes, 1), dtype=torch.float32)  # Dummy node features\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x.squeeze(dim=1)\n",
    "\n",
    "# Split the edge list into training and test sets\n",
    "train_edge_list, test_edge_list = train_test_split(edge_list, test_size=0.15, random_state=42)\n",
    "\n",
    "all_nodes = set(node for edge in edge_list for node in edge)\n",
    "num_nodes = len(all_nodes)\n",
    "\n",
    "model = GNN(num_nodes)\n",
    "\n",
    "# The optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Adjacency matrix\n",
    "    adjacency_matrix = torch.zeros((num_nodes, num_nodes), dtype=torch.float32)\n",
    "    for edge in train_edge_list:\n",
    "        adjacency_matrix[edge[0], edge[1]] = 1.0\n",
    "\n",
    "    predictions = model(adjacency_matrix)\n",
    "\n",
    "    targets = torch.zeros_like(predictions)\n",
    "    for edge in train_edge_list:\n",
    "        targets[edge[0], edge[1]] = 1.0\n",
    "\n",
    "    loss = criterion(predictions, targets)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Adjacency matrix for the entire graph\n",
    "adjacency_matrix_full = torch.zeros((num_nodes, num_nodes), dtype=torch.float32)\n",
    "for edge in edge_list:\n",
    "    adjacency_matrix_full[edge[0], edge[1]] = 1.0\n",
    "\n",
    "# Predictions for the entire graph\n",
    "predictions_full = model(adjacency_matrix_full)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_predictions = torch.zeros_like(predictions_full)\n",
    "for edge in test_edge_list:\n",
    "    test_predictions[edge[0], edge[1]] = 1.0\n",
    "\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions_full > threshold).int()\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "correct_predictions = (binary_predictions == test_predictions).sum().item()\n",
    "total_predictions = test_predictions.sum().item()\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def jaccard_prediction(G, k):\n",
    "    predictions = {}\n",
    "    for node1 in removed_nodes_set:\n",
    "        node1_friends = set(G.neighbors(node1))\n",
    "        scores = []\n",
    "        for node2 in list(G.nodes()):\n",
    "            if node1==node2: continue\n",
    "            if G.has_edge(node1, node2): continue\n",
    "            node2_friends = set(G.neighbors(node2))\n",
    "            total_friends = node1_friends.union(node2_friends)\n",
    "            numerator = sorted(w for w in node1_friends if w in node2_friends)\n",
    "            if len(total_friends)==0: score=0\n",
    "            else: score = len(numerator)/len(total_friends)\n",
    "            scores.append([node2, score])\n",
    "        \n",
    "        predicted_links = list(filter(lambda x: x[1] > k, scores))\n",
    "        if len(predicted_links)>0:\n",
    "            predictions[node1] = predicted_links\n",
    "    \n",
    "    predicted_edges = set()\n",
    "    for node1,scores in predictions.items():\n",
    "        for node2 in scores:\n",
    "            predicted_edges.add((node1, node2[0]))\n",
    "    return predicted_edges"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:06:13.006858Z",
     "start_time": "2023-12-03T18:06:12.998675Z"
    }
   },
   "id": "de36bb3800d32cb4"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def preferential_attachment_prediction(G, k):\n",
    "    predictions = {}\n",
    "    for node1 in removed_nodes_set:\n",
    "        scores = []\n",
    "        for node2 in list(G.nodes()):\n",
    "            if node1==node2: continue\n",
    "            if G.has_edge(node1, node2): continue\n",
    "            \n",
    "            score = G.degree(node1) * G.degree(node2)\n",
    "            scores.append([node2, score])\n",
    "        \n",
    "        predicted_links = list(filter(lambda x: x[1] > k, scores))\n",
    "        if len(predicted_links)>0:\n",
    "            predictions[node1] = predicted_links\n",
    "            \n",
    "    predicted_edges = set()\n",
    "    for node1,scores in predictions.items():\n",
    "        for node2 in scores:\n",
    "            predicted_edges.add((node1, node2[0]))\n",
    "    return predicted_edges\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:30:09.014239Z",
     "start_time": "2023-12-03T18:30:09.008989Z"
    }
   },
   "id": "9f23ba166ee4d2cd"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def assess_accuracy(predicted_edges, actual_edges):\n",
    "    actual_edge_set = set(actual_edges)\n",
    "    predicted_edge_set = set(predicted_edges)\n",
    "    \n",
    "    # Calculate True Positive, False Positive, True Negative, False Negative\n",
    "    true_positive = len(actual_edge_set.intersection(predicted_edge_set))\n",
    "    false_positive = len(predicted_edge_set - actual_edge_set)\n",
    "    false_negative = len(actual_edge_set - predicted_edge_set)\n",
    "    \n",
    "    # Calculate precision, recall, and f1 score\n",
    "    \n",
    "    # accuracy of positive predictions - if we predicted edge, is there actually edge?\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    \n",
    "    # if there is edge, % of time we predict edge accurately?\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    \n",
    "    # means of balancing\n",
    "    if precision == 0 and recall == 0: f1_score = 0\n",
    "    else: f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Precision: {precision:.2f}\", end=\" \")\n",
    "    print(f\"Recall: {recall:.2f}\", end = \" \")\n",
    "    print(f\"F1 Score: {f1_score:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:33:00.162334Z",
     "start_time": "2023-12-03T18:33:00.156038Z"
    }
   },
   "id": "64f1d6b1dc2d85f1"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard\n",
      "k=0:\n",
      "Precision: 0.01 Recall: 0.89 F1 Score: 0.02\n",
      "k=0.1:\n",
      "Precision: 0.04 Recall: 0.36 F1 Score: 0.07\n",
      "k=0.2:\n",
      "Precision: 0.09 Recall: 0.08 F1 Score: 0.08\n",
      "k=0.30000000000000004:\n",
      "Precision: 0.18 Recall: 0.02 F1 Score: 0.03\n",
      "k=0.4:\n",
      "Precision: 0.29 Recall: 0.00 F1 Score: 0.01\n",
      "k=0.5:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "k=0.6:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "k=0.7:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "k=0.7999999999999999:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "k=0.8999999999999999:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "k=0.9999999999999999:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n",
      "Preferential\n",
      "k=10000:\n",
      "Precision: 0.02 Recall: 0.23 F1 Score: 0.04\n",
      "k=20000:\n",
      "Precision: 0.04 Recall: 0.07 F1 Score: 0.05\n",
      "k=30000:\n",
      "Precision: 0.06 Recall: 0.02 F1 Score: 0.03\n",
      "k=40000:\n",
      "Precision: 0.08 Recall: 0.01 F1 Score: 0.01\n",
      "k=50000:\n",
      "Precision: 0.10 Recall: 0.00 F1 Score: 0.00\n",
      "k=60000:\n",
      "Precision: 0.00 Recall: 0.00 F1 Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard\")\n",
    "k = 0\n",
    "while k < 1:\n",
    "    jaccard_coefficient_graph_copy = removed_edges_graph.copy()\n",
    "    jaccard_predicted_edges = jaccard_prediction(jaccard_coefficient_graph_copy, k)\n",
    "    if len(jaccard_predicted_edges) == 0:\n",
    "        break\n",
    "    print(f\"k={k}:\")\n",
    "    assess_accuracy(jaccard_predicted_edges, removed_edges)\n",
    "    k += 0.1\n",
    "\n",
    "print(\"Preferential\")\n",
    "k = 10000\n",
    "while k < 100000:\n",
    "    preferential_graph_copy = removed_edges_graph.copy()\n",
    "    preferential_predicted_edges = preferential_attachment_prediction(preferential_graph_copy, k)\n",
    "    if len(preferential_predicted_edges) == 0:\n",
    "        break\n",
    "    print(f\"k={k}:\")\n",
    "    assess_accuracy(preferential_predicted_edges, removed_edges)\n",
    "    k += 10000"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T18:34:41.646356Z",
     "start_time": "2023-12-03T18:33:03.203241Z"
    }
   },
   "id": "6e98659b80d92728"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ad919cf556821c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
